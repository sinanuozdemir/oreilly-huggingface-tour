# Hugging Face in 4 Hours

![HF](images/hf.png)

![O'Reilly](images/oreilly.png)

This repository contains Jupyter notebooks for the courses ["Hugging Face in 4 Hours"](https://learning.oreilly.com/live-events/hugging-face-in-4-hours/0790145056533/0790145056525/) by [Sinan Ozdemir](https://sinanozdemir.ai). Published by Pearson, the course covers effective best practices and industry case studies in using Large Language Models (LLMs) from Hugging Face.

Hugging Face is the worldâ€™s largest hub for modern AI models and provides access for anyone to use, train, and deploy these models with ease! This course is a gateway to mastering Hugging Face's tools for NLP, offering an inclusive curriculum for non-developers and developers alike to learn the ecosystem. With a spotlight on interactive learning and practical application, attendees will acquire the skills to fine-tune pre-trained models for a variety of NLP tasks and understand how to deploy these models with efficiency.

### Course Set-Up

- Jupyter notebooks can be run alongside the instructor, but you can also follow along without coding by viewing pre-run notebooks here.

### Notebooks

- `Intro to HF.ipynb`: [Introduction to Hugging Face](notebooks/Intro%20to%20HF.ipynb)

	- `More on 3rd party inference` - [Notebook](notebooks/third_party_inference.ipynb)

- `Prototyping with HF.ipynb`: [notebooks/Prototyping with Hugging Face](notebooks/Prototyping%20with%20HF.ipynb)

- `BERT vs GPT`: [notebooks/Fine-tuning BERT for Classification](notebooks/BERT%20vs%20GPT.ipynb)


- [`Introduction to SmolAgents`](notebooks/SmolAgents.ipynb) - HuggingFaces's AI Agent SDK with built in ReAct and CodeAgent functionality

- `Multimodality with HF.ipynb`: A brief workshop in using some multi-modal models from HF
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1zYSzDuYFa_cbRlti3scUjfmvradK8Sf4?usp=sharing)


  - For more on Multimodality, check out my [livesession on the topic](https://github.com/sinanuozdemir/oreilly-multimodal-ai)

---

- **Advanced:** `fine_tuning_llama_3`: A workshop in fine-tuning Llama 3.1 with instructional data and incorporating further pre-training to update it's knowledge base
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1sUXME3CcDEqp1eF8j5-z7bdUh2whKvDO?usp=sharing)


## Streamlit

- See [this README](streamlit/chat/README.md) for info on how to run our streamlit app


## LLM Quantization

- [Quantizing Llama-3 dynamically](https://colab.research.google.com/drive/12RTnrcaXCeAqyGQNbWsrvcqKyOdr0NSm?usp=sharing)

- [Working with GGUF (with a GPU)](https://colab.research.google.com/drive/1D6k-BeuF8YRTR8BGi2YYJrSOAZ6cYX8Y?usp=sharing)


## Further Resources

- [Other Useful Links](https://learning.oreilly.com/playlists/2953f6c7-0e13-49ac-88e2-b951e11388de/)
